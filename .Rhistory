ggplot(d, aes( y= meanCons, x= lims))
+ geom_line()
+ geom_point()
+ geom_errorbar(aes(ymin=meanCons-sdCons, ymax=meanCons+sdCons), width=.2)
#+ ggtitle("Lexical consistence = f(keyword limit)")
#+ xlab("keyword limit") + ylab("mean consistence")
meanCons
lims
d = data.frame(meanCons,sdCons,lims)
ggplot(d, aes( y= meanCons, x= lims))
ggplot(d, aes( y= meanCons, x= lims))+ geom_line()
+ geom_errorbar(aes(ymin=meanCons-sdCons, ymax=meanCons+sdCons), width=.2)
ggplot(d, aes( y= meanCons, x= lims))+ geom_line()
+ geom_point()
+ geom_errorbar(aes(ymin=meanCons-sdCons, ymax=meanCons+sdCons), width=.2)
d = data.frame(meanCons,sdCons,lims)
ggplot(d, aes( y= meanCons, x= lims))+
geom_line() +
geom_point() +
geom_errorbar(aes(ymin=meanCons-sdCons, ymax=meanCons+sdCons), width=.2) +
ggtitle("Lexical consistence = f(keyword limit)") +
xlab("keyword limit") + ylab("mean consistence")
install.packages("spatstat")
install.packages("spatstat")
library(spatstat)
beginner
vignette('getstart')
vignette('getstart')
library(raster)
install.oackages("raster")
install.packages("raster")
library(raster)
help("raster")
raw <- raster("/Users/Juste/Documents/ComplexSystems/CityNetwork/Data/PopulationDensity/bassin_parisien.tif")
install.packages('rgdal')
library(RColorBrewer)
library(rgdal)
library(ggplot2)
install.packages("ggplot2")
install.packages("RColorBrewer")
raw <- raster("/Users/Juste/Documents/ComplexSystems/CityNetwork/Data/PopulationDensity/bassin_parisien.tif")
raw <- raster("/Users/Juste/Documents/ComplexSystems/CityNetwork/Data/PopulationDensity/bassin_parisien.tif")
raw
help(opening)
w <- as.owin(raw)
w <- owin(raw)
help(im)
w <- owin(im(raw))
im(raw)
help(raster)
im(as.matrix(raw))
w <- owin(im(as.matrix(raw)))
w <- as.owin(im(as.matrix(raw)))
w
as.matrix(w)
as.matrix(w)
opening(w)
opening(w,10)
as.matrix(raw)
help(unique)
unique(raw)
raw
help(find)
binmat<- as.matrix(raw)>10000
sum(binmat)
binmat
binmat<- as.matrix(raw)
binmat
help(as.matrix)
help(dim)
dim(binmat)
help(is.na)
sum(!is.na(as.matrix(raw)))
binmat<- ((!is.na(as.matrix(raw)))%*%as.matrix(raw))>10000
is.na(as.matrix(raw))
help(as.int)
na.omit(as.matrix(raw))
na.omit(c(NA,1))
na.omit(c(NA,1))[1]
binmat<- (na.omit(as.matrix(raw))[1])>10000
sum(binmat)
na.omit(as.matrix(raw))[1]
na.omit(as.matrix(raw))
help(na.omit)
binmat<- (as.matrix(na.omit(as.matrix(raw))))>10000
sum(binmat)
binmat
w <- as.owin(im(as.matrix(raw)))
plot(w)
raw <- raster("/Users/Juste/Documents/ComplexSystems/CityNetwork/Data/PopulationDensity/raw/uk-lr.tif")
m = as.matrix(raw)
m[is.na(m)] <- 0
threshold = 10
sum(m>threshold)/length(m)
threshold = 100
sum(m>threshold)/length(m)
binmat<- m>threshold
sum(binmat)/length(m)
w <- owin(mask=binmat)
library(spatstat)
w <- owin(mask=binmat)
radius=3
rep=15
o=w
for(i in 1:rep){
show(paste("it",i))
o <- closing(o,radius)
o <- opening(o,radius)
}
m = as.matrix(o)
library(rlist)
propagate <- function(m,indices,ii,jj,n){
pile = list(c(ii,jj))
while(length(pile)>0){
# unstack first
coords = list.take(pile,1)[[1]] ; pile = list.remove(pile,1);
i=coords[1];j=coords[2];
# update indices
indices[i,j]=n
#stack neighbors of conditions are met
if(i>1){if(indices[i-1,j]==0&&m[i-1,j]==TRUE){pile = list.prepend(pile,c(i-1,j))}}
if(i<nrow(m)){if(indices[i+1,j]==0&&m[i+1,j]==TRUE){pile = list.prepend(pile,c(i+1,j))}}
if(j>1){if(indices[i,j-1]==0&&m[i,j-1]==TRUE){pile = list.prepend(pile,c(i,j-1))}}
if(j<ncol(m)){if(indices[i,j+1]==0&&m[i,j+1]==TRUE){pile = list.prepend(pile,c(i,j+1))}}
}
return(indices)
}
connexAreas <- function(m){
indices <- matrix(data=rep(0,nrow(m)*ncol(m)),nrow=nrow(m),ncol=ncol(m))
maxArea = 0
for(i in 1:nrow(m)){
for(j in 1:ncol(m)){
# if colored but not marked, mark recursively
#   -- necessarily a new area
if(m[i,j]==TRUE&&indices[i,j]==0){
maxArea = maxArea + 1
#show(paste("Prop",i,j," - area ",maxArea))
indices <- propagate(m,indices,i,j,maxArea)
}
}
}
)
)
connexAreas <- function(m){
indices <- matrix(data=rep(0,nrow(m)*ncol(m)),nrow=nrow(m),ncol=ncol(m))
maxArea = 0
for(i in 1:nrow(m)){
for(j in 1:ncol(m)){
# if colored but not marked, mark recursively
#   -- necessarily a new area
if(m[i,j]==TRUE&&indices[i,j]==0){
maxArea = maxArea + 1
#show(paste("Prop",i,j," - area ",maxArea))
indices <- propagate(m,indices,i,j,maxArea)
}
}
}
# use indices to create list of coordinates
areas = list()
for(a in 1:maxArea){
areas=list.append(areas,which(indices==a))
}
return(areas)
}
connexAreas <- function(m){
indices <- matrix(data=rep(0,nrow(m)*ncol(m)),nrow=nrow(m),ncol=ncol(m))
maxArea = 0
for(i in 1:nrow(m)){
for(j in 1:ncol(m)){
# if colored but not marked, mark recursively
#   -- necessarily a new area
if(m[i,j]==TRUE&&indices[i,j]==0){
maxArea = maxArea + 1
show(paste("Prop",i,j," - area ",maxArea))
indices <- propagate(m,indices,i,j,maxArea)
}
}
}
# use indices to create list of coordinates
areas = list()
for(a in 1:maxArea){
areas=list.append(areas,which(indices==a))
}
return(areas)
}
areas = connexAreas(m)
sizes =  unlist(list.apply(areas,length))
sizes
hist(log(sizes),breaks=100)
hist(sizes)
hist(sizes,breaks=100)
help(hist)
help(pdf)
help(hist)
hist(log(sizes),breaks=100,plot=FALSE)
plot(h$mids,log(h$counts))
h = hist(log(sizes),breaks=100,plot=FALSE)
plot(h$mids,log(h$counts))
writeRaster(raster(as.im(o)),paste0("/Users/Juste/Documents/ComplexSystems/CityNetwork/Data/PopulationDensity/processed/uk_closed_opened",radius,"_rep",rep,".tif"),"GTiff")
help(exec)
help('exec')
help('system')
help('Moran')
raw <- raster("/Users/Juste/Documents/ComplexSystems/CityNetwork/Data/PopulationDensity/raw/bp_300x500.tif")
raw <- raster("/Users/Juste/Documents/ComplexSystems/CityNetwork/Data/PopulationDensity/raw/bp_500x300.tif")
library(raster)
library(rgdal)
raw <- raster("/Users/Juste/Documents/ComplexSystems/CityNetwork/Data/PopulationDensity/raw/bp_500x300.tif")
raw <- raster("/Users/Juste/Documents/ComplexSystems/CityNetwork/Data/PopulationDensity/raw/bassin_parisien_500x300.tif")
Moran(raw)
Moran(raw,w=matrix(1,10,10))
Moran(raw,w=matrix(1,11,11))
Moran(raw,w=matrix(1,51,51))
Moran(raw,w=matrix(1,101,101))
r <- raster("/Users/Juste/Documents/ComplexSystems/CityNetwork/Data/PopulationDensity/raw/bassin_parisien_500x300.tif")
cumsum
cumsum(matrix(1,10,10))
help('rep')
cumsum(matrix(1,1,10))
cumsum(matrix(1,10,1))
rep(cumsum(matrix(1,10,1)),10)
matrix(rep(cumsum(matrix(1,2*N+1,1)),2*N+1))
N = 10
matrix(rep(cumsum(matrix(1,2*N+1,1)),2*N+1))
matrix(rep(cumsum(matrix(1,2*N+1,1)),2*N+1),nrow=2*N+1)
matrix(rep(cumsum(matrix(1,2*N+1,1)),2*N+1),nrow=2*N+1) - N
matrix(rep(cumsum(matrix(1,2*N+1,1)),2*N+1),nrow=2*N+1) - N - 1
d = matrix(rep(cumsum(matrix(1,2*N+1,1)),2*N+1),nrow=2*N+1) - N - 1
t(d)
1 / d
1 / (d + t(d))
d = (matrix(rep(cumsum(matrix(1,2*N+1,1)),2*N+1),nrow=2*N+1) - N - 1) ^ 2
d
1 / sqrt(d + t(d))
w = 1 / sqrt(d + t(d))
w[w=Inf]=1
w
w[w==Inf]=1
w
N = 20
d = (matrix(rep(cumsum(matrix(1,2*N+1,1)),2*N+1),nrow=2*N+1) - N - 1) ^ 2
w = 1 / sqrt(d + t(d))
w[w==Inf]=1
Moran(r,w)
N = 10
d = (matrix(rep(cumsum(matrix(1,2*N+1,1)),2*N+1),nrow=2*N+1) - N - 1) ^ 2
w = 1 / sqrt(d + t(d))
w[w==Inf]=1
# Moran with these weights
Moran(r,w)
help(seq)
spatialWeights <- function (N){
d = (matrix(rep(cumsum(matrix(1,2*N+1,1)),2*N+1),nrow=2*N+1) - N - 1) ^ 2
w = 1 / sqrt(d + t(d))
w[w==Inf]=1
return(w)
}
spatialWeights(10)
Moran(r,w)
morans = c()
for(n in seq(from=10,to=100,by=10)){
show(n)
morans = append(morans,Moran(r,n))
}
morans = append(morans,Moran(r,spatialWeights(n)))
morans = c()
for(n in seq(from=10,to=100,by=10)){
show(n)
morans = append(morans,Moran(r,spatialWeights(n)))
}
plot(seq(from=10,to=100,by=10),morans)
for(n in seq(from=110,to=150,by=10)){
show(n)
morans = append(morans,Moran(r,spatialWeights(n)))
}
plot(seq(from=10,to=150,by=10),morans)
raster(matrix(1,10,10))
r <- raster("/Users/Juste/Documents/ComplexSystems/CityNetwork/Data/PopulationDensity/raw/bassin_parisien_500x300.tif")
r
m = as.matrix(r)
m[is.na(m)] <- 0
r = raster(m)
r
spatialWeights <- function (N){
d = (matrix(rep(cumsum(matrix(1,2*N+1,1)),2*N+1),nrow=2*N+1) - N - 1) ^ 2
w = 1 / sqrt(d + t(d))
w[w==Inf]=1
return(w)
}
morans = c()
N = seq(from=10,to=50,by=10)
for(n in N){
show(n)
morans = append(morans,Moran(r,spatialWeights(n)))
}
plot(N,morans)
morans = c()
N = seq(from=10,to=150,by=10)
for(n in N){
show(n)
morans = append(morans,Moran(r,spatialWeights(n)))
}
plot(N,morans)
help(permutation)
sample(1:20)
sample(1:20)
sample(1:20)
sample(1:20)
sample(1:20)
sample(1:20)
sample(1:20)
sample(m)
shuffleData <- function(d){
m = as.matrix(d)
m[is.na(m)] <- 0
return(raster(sample(m)))
}
shuffleData(r)
shuffleData <- function(d){
m = as.matrix(d)
m[is.na(m)] <- 0
return(raster(as.matrix(sample(m)))
}
shuffleData <- function(d){
m = as.matrix(d)
m[is.na(m)] <- 0
return(raster(as.matrix(sample(m))))
}
shuffleData(r)
nrows(m)
nrow(m)
shuffleData <- function(d){
m = as.matrix(d)
m[is.na(m)] <- 0
return(raster(as.matrix(sample(m),nrows=nrow(m))))
}
nrow(m)
shuffleData(r)
r <- raster("/Users/Juste/Documents/ComplexSystems/CityNetwork/Data/PopulationDensity/raw/bassin_parisien_500x300.tif")
m = as.matrix(r)
m[is.na(m)] <- 0
r = raster(m)
r
# takes a raster and returns uniformally shuffled data
shuffleData <- function(d){
m = as.matrix(d)
m[is.na(m)] <- 0
return(raster(matrix(sample(m),nrows=nrow(m))))
}
shuffleData(r)
shuffleData <- function(d){
m = as.matrix(d)
m[is.na(m)] <- 0
return(raster(matrix(sample(m),nrow=nrow(m))))
}
shuffleData(r)
N = seq(from=10,to=20,by=10)
Nrep = 1
null_morans = matrix(0,length(N),Nrep)
for(n in 1:length(N)){
show(n)
for(k in 1:Nrep){
null_morans[n,k] = Moran(shuffleData(r),spatialWeights(N[n]))
}
}
null_morans
N = seq(from=10,to=150,by=10)
Nrep = 10
null_morans = matrix(0,length(N),Nrep)
null_morans
for(n in 1:length(N)){
for(k in 1:Nrep){
show(paste(n,' - ',k))
null_morans[n,k] = Moran(shuffleData(r),spatialWeights(N[n]))
}
}
null_morans
mean(null_morans)
help(mean)
man(save)
help(save)
save(null_morans,morans,file="moran.Rdata",ascii=TRUE)
setwd('~/Documents/ComplexSystems/RobustnessDiscrepancy')
load('.RData')
carToWork <- function(arrs){
coords = buildings@coords[arr_buildings%in% arrs,]
# sample for perf reasons
coords = coords[sample(1:length(coords[,1]),floor(length(coords[,1])*0.05)),]
n=length(coords[,1])
inds=sample(1:n,size=floor(0.1*n))
with_car = coords[inds,]
dests = matrix(data=c(runif(length(with_car[,1]),min=2.241859,max=2.428637),
runif(length(with_car[,1]),min=48.79654 ,max=48.9171)),nrow=length(with_car[,1]))
d <- (dests - with_car)^2
d <- sqrt(d[,1]+d[,2]) / dmax
indic = mean(d)
dat = matrix(0,n,3)
dat[inds,3]=d
dat[,1:2]=coords
res=list()
res[[1]]=dat
res[[2]]=1-indic
return(res)
}
# mean vehicle flow per street : number of lanes, pedestrian streets, etc
#  -> normalized by a max flow. Log-normal distrib fits well such empirical var.
#  (street hierarchy == betweeness == preferential attchment)
vehicleFlow <- function(arrs){
coords = roads_raw[arr_streets%in% arrs,]
coords = coords[sample(1:length(coords[,1]),floor(length(coords[,1])*0.05)),]
# generate hierarchy
flows <- rlnorm(length(coords[,1]),0,0.01)/2
flows<- flows/max(flows)
dat = matrix(0,length(coords[,1]),4)
dat[,1:3]=coords
dat[,4] = flows
# compute indic
indic = mean(flows*coords[,3]/max(coords[,3]))
res=list()
res[[1]]=dat
res[[2]]=1-indic
return(res)
}
# more qualitative indicator : proportion of pedestrian streets
#
pedestrianStreets <- function(arrs){
coords = roads_raw[arr_streets%in% arrs,]
coords = coords[sample(1:length(coords[,1]),floor(length(coords[,1])*0.05)),]
dat = matrix(0,length(coords[,1]),3)
dat[,1:3]=coords
tot_length=sum(coords[,3])
# set non pedestrian roads length to zero
dat[sample(1:length(dat[,1]),floor(length(dat[,1])*0.8)),3] = 0
indic = sum(dat[,3])/tot_length
res=list()
res[[1]]=dat
res[[2]]=indic
return(res)
}
# compute robustness ratio
rawBound <- function(indics,arrs){
weights <- c()
discrs <- c()
for(i in 1:length(indics)){
r = indics[i][[1]](arrs)
weights = append(weights,r[[2]])
#show(dim(r[[1]]))
discrs = append(discrs,discrepancyCriteria(r[[1]],type=c('L2'))$DisL2)
}
res=list()
#mem values
res[[1]]=weights
weights=weights/sum(weights)
#show(weights)
#show(discrs)
res[[2]]=sum(weights*discrs)
return(res)
}
# test
all = c(carToWork,vehicleFlow,pedestrianStreets)
rawBound(all,c(10))
library(DiceDesign)
rawBound <- function(indics,arrs){
weights <- c()
discrs <- c()
for(i in 1:length(indics)){
r = indics[i][[1]](arrs)
weights = append(weights,r[[2]])
#show(dim(r[[1]]))
discrs = append(discrs,discrepancyCriteria(r[[1]],type=c('L2'))$DisL2)
}
res=list()
#mem values
res[[1]]=weights
weights=weights/sum(weights)
#show(weights)
#show(discrs)
res[[2]]=sum(weights*discrs)
return(res)
}
# test
all = c(carToWork,vehicleFlow,pedestrianStreets)
rawBound(all,c(10))
# OK -> let compute for all arrs
i1=list();i2=list();i3=list();bound=list();
for(i in 1:20){
i1[[i]]=c(0);i2[[i]]=c(0);i3[[i]]=c(0);bound[[i]]=c(0)
}
nrep = 50
for(n in 1:nrep){
show(n)
for(i in 1:20){
r=rawBound(all,c(i))
i1[[i]]=append(i1[[i]],r[[1]][1]);i2[[i]]=append(i2[[i]],r[[1]][2]);i3[[i]]=append(i3[[i]],r[[1]][3])
bound[[i]]=append(bound[[i]],r[[2]])
}
}
# produce final mat
res = matrix("",20,5)
for(i in 1:20){
# compare to first arr
res[i,1] = paste(i,"th")
res[i,2] = paste(sprintf("%07.6f", mean(i1[[i]][2:51])),"$\\pm$",sprintf("%07.6f",sd(i1[[i]][2:51])))
res[i,3] = paste(sprintf("%07.6f",mean(i2[[i]][2:51])),"$\\pm$",sprintf("%07.6f",sd(i2[[i]][2:51])))
res[i,4] = paste(sprintf("%07.6f",mean(i3[[i]][2:51])),"$\\pm$",sprintf("%07.6f",sd(i3[[i]][2:51])))
res[i,5] = paste(sprintf("%07.6f",mean(bound[[i]][2:51]/bound[[1]][2:51])),"$\\pm$",sprintf("%07.6f",sd(bound[[i]][2:51]/bound[[1]][2:51])))
}
res
knit('testknitr.Rnw')
library(knitr)
knit('testknitr.Rnw')
knit('Models/testknitr.Rnw')
